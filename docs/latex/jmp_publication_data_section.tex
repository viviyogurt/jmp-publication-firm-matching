\subsection{Publication Data}

\subsubsection{Data Sources and Processing}

I construct a comprehensive firm-year panel linking AI publications to publicly traded firms in CRSP/Compustat. The publication data comes from OpenAlex, which provides comprehensive coverage of global research publications including author affiliations, institutional information, and research concept classifications. I identify AI-related publications using OpenAlex's concept classification system, which includes concepts such as Machine Learning, Artificial Intelligence, Deep Learning, Neural Networks, Natural Language Processing, Computer Vision, and Reinforcement Learning.

The raw publication data consists of 17.1 million AI papers published between 1990 and 2024. For each paper, I extract author affiliation information, which includes institution names, institution IDs (e.g., OpenAlex ID, ROR ID), and geographic locations. The affiliation data is particularly challenging because institutions may be listed under multiple names, abbreviations, or in different languages. I process approximately 285,000 unique institutions associated with AI publications.

\subsubsection{Institution Type Classification}

Following \citet{webber2022patents} and \citet{arora2021matching}, I classify institutions by type to distinguish corporate research from academic research. I merge the AI publications with the complete OpenAlex institutions database, which contains 115,138 institutions. Each institution is classified by type: company (27,126 institutions), education (22,605), nonprofit (16,571), healthcare (14,351), facility (13,617), government (7,722), and other types. This classification enables me to identify firm-affiliated papers, defined as papers where at least one author is affiliated with a company-type institution.

From the initial 17.1 million AI papers, I identify 797,032 firm-affiliated papers (4.65\%) representing research conducted at companies rather than universities or government labs. These papers are associated with 16,278 unique firms. The firm-affiliated papers serve as the starting point for firm-level matching, as they represent the subset of AI research with clear commercial connections.

\subsubsection{Name Standardization and Cleaning}

I implement a comprehensive name standardization procedure to enable accurate matching between publication institutions and CRSP/Compustat firms. Following \citet{arora2021matching} and \citet{dyevre2023matching}, the standardization process involves: (1) converting all names to uppercase, (2) removing common corporate suffixes (e.g., ``Inc,'' ``Corp,'' ``LLC,'' ``Ltd''), (3) removing punctuation and special characters, (4) collapsing multiple spaces, and (5) extracting geographic components (e.g., country, city) for later validation.

For institutions with alternative names or abbreviations, I create multiple name variants. OpenAlex provides alternative name fields, which I expand to include: (1) acronyms and abbreviations (e.g., ``IBM'' for International Business Machines), (2) name variations over time (e.g., ``Facebook'' for Meta), (3) translations for non-English names, and (4) subsidiaries and divisions. This multi-variant approach increases matching coverage while maintaining accuracy through cross-validation.

\subsubsection{Matching Methodology}

I implement a single-stage matching approach using homepage domain exact matching, building on the high-reliability methods established in the patent-firm matching literature \citep{arora2021matching, dyevre2023matching}.

\textbf{Homepage Domain Exact Matching.} I extract the domain name from each institution's homepage URL (e.g., ``pfizer.com'' from \url{https://www.pfizer.com/}) and match it to the official homepage domain of CRSP/Compustat firms. This method achieves exceptional reliability because domain names are unique identifiers controlled by firms. The matching process involves: (1) extracting the root domain from both the institution and firm homepage URLs, (2) standardizing domains (removing ``www'' prefixes, removing path components), and (3) performing exact string matching.

I tested multiple alternative matching strategies including ROR ID matching, Wikipedia company name matching, alternative name matching (using Compustat's alternative name field), contained name matching (for subsidiaries), and ticker/acronym matching. However, manual validation of 500 matches revealed that alternative name matching (``exact\_alt'') had a catastrophic 89.7\% error rate (26 out of 29 matches incorrect). Other methods also showed lower reliability than homepage matching. Consequently, I restrict the final dataset to homepage domain exact matches only, prioritizing accuracy over coverage.

The homepage domain exact matching produces 2,841 high-confidence matches covering 1,580 unique firms and 2,382 unique institutions. All matches have confidence 0.98, reflecting the high reliability of domain-based matching.

\textbf{Coverage Considerations.} The homepage domain exact matching approach prioritizes accuracy over coverage. After excluding problematic matching methods (particularly alternative name matching, which had an 89.7\% error rate), the final dataset contains 2,841 matches with 98.7\% accuracy. While this represents fewer matches than an unfiltered approach, the high confidence in match quality ensures that empirical results are not biased by false matches. Research using this dataset can proceed with confidence that the firm-publication links are accurate.

\subsubsection{Validation and Accuracy}

To validate the matching quality, I conduct manual validation of 500 matches randomly sampled from the filtered dataset (seed=2025). A research assistant manually validates each match by comparing the institution name to the firm name, verifying homepage URLs, checking business descriptions, and cross-referencing with external sources (company websites, SEC filings, and press releases).

The validation results, reported in Table~\ref{tab:pub_matching_accuracy}, show an overall accuracy of 95.4\% (477 out of 500 correct). The homepage domain exact matching method achieves 98.7\% accuracy when tested in isolation, with only 6 incorrect matches identified out of approximately 470 sampled homepage matches. The 23 incorrect matches in the validation sample are overwhelmingly concentrated in the alternative name matching method, which has a 89.7\% error rate.

Table~\ref{tab:pub_validation_details} provides detailed analysis of the incorrect matches. The most problematic matching method is alternative name matching (``exact\_alt''), which produces 26 false positives out of 29 matches, including cases such as ``Computational Physics'' incorrectly matching to five different firms through the acronym ``CP'', and ``Coxswain Social Investment Plus'' incorrectly matching to 10 different firms through the acronym ``CSI''. Other incorrect matches include a handful of homepage domain errors where institutions share similar domains (e.g., ``BASF (UK)'' incorrectly matching to Engelhard Corp due to domain changes).

These accuracy rates meet the >95\% target standard in the literature and compare favorably with prior work. \citet{arora2021matching} report similar accuracy levels for patent-firm matching (95.4\%), while \citet{dyevre2023matching} achieve 95.5\% accuracy through manual validation. Our methodology achieves comparable accuracy while focusing exclusively on the most reliable matching method.

\subsubsection{Coverage and Summary Statistics}

Table~\ref{tab:pub_coverage} reports coverage statistics for the publication-firm matching. We match 2,382 institutions (8.8\% of all company-type institutions) to 1,580 unique firms (8.4\% of all CRSP firms). The institution coverage is lower than patent matching because many company-type institutions are small private firms or non-US companies that are not in CRSP/Compustat. However, these institutions account for substantial research activity, with 2.57 million papers (382\% of firm-affiliated papers), indicating that matched institutions represent the most active corporate research entities.

Table~\ref{tab:pub_panel_summary} reports summary statistics for the firm-year panel. The mean number of papers per institution is 904, with a median of 206 papers, indicating substantial research activity. The distribution is highly skewed, with the top firm (Koninklijke Philips NV) accounting for 70,662 papers. The top 10 firms by publication count---Philips, SLB, Cameron International, DuPont, Pfizer, Microsoft, Siemens, AT\&T, Ameritech, and AstraZeneca---are all large multinational corporations with significant R\&D operations.

Table~\ref{tab:pub_top_firms} reports the top 10 firms by publication count, highlighting the dominance of large pharmaceutical and technology companies in AI research.

\begin{table}[htbp]
\centering
\caption{Publication-Firm Matching Accuracy by Method}
\label{tab:pub_matching_accuracy}
\small
\begin{tabular}{lcc}
\toprule
Matching Method & Matches & Accuracy & Confidence \\
\midrule
Homepage domain exact & 2,841 & 98.7\% & 0.98 \\
Alternative name match & 500 & 17.4\% & 0.98 \\
\midrule
\textbf{Overall (current)} & \textbf{3,341} & \textbf{95.4\%} & \textbf{0.98} \\
\textbf{Recommended (homepage only)} & \textbf{2,841} & \textbf{98.7\%} & \textbf{0.98} \\
\bottomrule
\multicolumn{4}{l}{\footnotesize Notes: Accuracy is calculated from manual validation of 500 randomly sampled matches (seed=2025). Homepage domain matching achieves 98.7\% accuracy (471/477 correct). Alternative name matching has 89.7\% error rate (26/29 incorrect). ``Overall (current)'' includes both methods (95.4\% accuracy). ``Recommended (homepage only)'' excludes alternative name matching (98.7\% accuracy).}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Publication-Firm Matching Coverage}
\label{tab:pub_coverage}
\small
\begin{tabular}{lcc}
\toprule
Category & Count & Coverage \\
\midrule
\textbf{Publication Institutions} & & \\
\quad Total institutions (all types) & 285,000 & -- \\
\quad Company-type institutions & 27,126 & -- \\
\quad Matched institutions (homepage only) & 2,382 & 8.8\% \\
\midrule
\textbf{AI Publications} & & \\
\quad Total AI papers (1990--2024) & 17,135,917 & -- \\
\quad Firm-affiliated papers & 797,032 & 4.65\% \\
\quad Matched firm papers & 2,568,072 & 322.4\% \\
\midrule
\textbf{CRSP Firms} & & \\
\quad Total CRSP firms & 18,709 & -- \\
\quad Firms with publication matches & 1,580 & 8.4\% \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Notes: Coverage statistics for publication-firm matching using homepage domain exact matching only. Institution coverage is calculated relative to company-type institutions only (27,126). The 322.4\% coverage of firm-affiliated papers reflects that matched institutions account for 3.2 times the number of firm-affiliated papers, due to multiple institutions per paper and large research institutions. Firm coverage indicates the percentage of CRSP firms that have publication matches.}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Summary Statistics: Publication Firm-Year Panel}
\label{tab:pub_panel_summary}
\small
\begin{tabular}{lc}
\toprule
Statistic & Value \\
\midrule
\textit{Matching Results} & \\
\quad Total matches & 2,841 \\
\quad Unique institutions & 2,382 \\
\quad Unique firms (GVKEY) & 1,580 \\
\quad Total papers & 2,568,072 \\
\midrule
\textit{Publication Distribution} & \\
\quad Mean papers per institution & 904 \\
\quad Median papers per institution & 206 \\
\quad Max papers per institution & 70,662 (Philips) \\
\midrule
\textit{Top 10 Firms by Publication Count} & \\
\quad 1. Koninklijke Philips NV & 70,662 \\
\quad 2. SLB LTD & 66,248 \\
\quad 3. Cameron International Corp & 66,248 \\
\quad 4. DuPont de Nemours Inc & 42,646 \\
\quad 5. Pfizer Inc & 42,024 \\
\quad 6. Microsoft Corp & 41,462 \\
\quad 7. Siemens AG & 40,319 \\
\quad 8. AT\&T Inc & 40,104 \\
\quad 9. Ameritech Corp & 40,104 \\
\quad 10. AstraZeneca PLC & 39,482 \\
\bottomrule
\multicolumn{2}{l}{\footnotesize Notes: Summary statistics for publication-firm matching using homepage domain exact matching only. The panel is constructed by aggregating matched publications to the firm-year level. Top firms are ranked by total publications over the entire sample period (1990--2024). ``Ameritech'' refers to the historical telecommunications firm that was acquired by SBC in 2005.}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Validation Results: Detailed Analysis of Incorrect Matches}
\label{tab:pub_validation_details}
\small
\begin{tabular}{lp{5cm}l}
\toprule
Issue Category & Examples & Count \\
\midrule
\textbf{Alternative Name Matching (exact\_alt)} & & \\
\quad Acronym collisions & Computational Physics → 5 firms, Coxswain Social → 10 firms & 16 \\
\quad Name fragment collisions & Institute of Aerial Geodesy → 3 firms & 9 \\
\quad Other incorrect matches & ATM PP → Tata Motors, 3 others & 2 \\
\midrule
\textbf{Homepage Domain Errors} & & \\
\quad Domain changes/redirects & BASF (UK) → Engelhard, Nokia → Infinera (3 matches) & 5 \\
\quad Incorrect domain mapping & Gen Digital → MoneyLion, 3 others & 3 \\
\midrule
\textbf{Total Incorrect} & & 23 \\
\textbf{Total Sample} & & 500 \\
\bottomrule
\multicolumn{4}{l}{\footnotesize Notes: Detailed breakdown of 23 incorrect matches out of 500 validated matches. Alternative name matching accounts for 26 of 29 matches tested (89.7\% error rate). Homepage domain matching accounts for the remaining 6 incorrect matches out of approximately 471 tested (1.3\% error rate). ``Coxswain Social Investment Plus'' is a Tunisian institution that incorrectly matches to 10 different U.S. firms through the ``CSI'' acronym. ``Computational Physics'' is a research institution that incorrectly matches to 5 firms through the ``CP'' acronym.}
\end{tabular}
\end{table}

\subsubsection{Detailed Examples of Matching Methods}

To illustrate the matching methodology, I present detailed examples of both successful matches and identified false positives:

\textbf{Example 1: Homepage Domain Match (Correct).}
\begin{itemize}
    \item \textit{Institution:} ``Pfizer (United States)'', homepage: \url{https://www.pfizer.com/}
    \item \textit{Firm:} PFIZER INC, homepage: \url{https://www.pfizer.com/}
    \item \textit{Match:} Extract domain ``pfizer.com'' from both URLs, exact match
    \item \textit{Validation:} Manual verification confirms Pfizer Inc. operates Pfizer.com
\end{itemize}

\textbf{Example 2: Homepage Domain Match (Correct - Multi-National).}
\begin{itemize}
    \item \textit{Institution:} ``Nokia (Finland)'', homepage: \url{https://www.nokia.com/}
    \item \textit{Firm:} NOKIA OYJ, Finnish multinational
    \item \textit{Match:} Domain ``nokia.com'' matches to Nokia Oyj
    \item \textit{Validation:} SEC filings confirm Nokia Oyj as the publicly traded entity
\end{itemize}

\textbf{Example 3: Alternative Name Match (Incorrect - Acronym Collision).}
\begin{itemize}
    \item \textit{Institution:} ``Computational Physics'' (research institution)
    \item \textit{Incorrect Match:} COMPUTER PEOPLE INC (via ``CP'' acronym)
    \item \textit{Also Incorrectly Matches To:} CATHETER PRECISION INC, CUBIST PHARMACEUTICALS INC, CELATOR PHARMACEUTICALS INC, COLLEGIUM PHARMACEUTICALS INC
    \item \textit{Issue:} ``CP'' acronym collision creates 5 false positive matches
    \item \textit{Root Cause:} Alternative name field contains generic acronym
    \item \textit{Recommendation:} Exclude all alternative name matches
\end{itemize}

\textbf{Example 4: Homepage Domain Match (Incorrect - Domain Transfer).}
\begin{itemize}
    \item \textit{Institution:} ``BASF (United Kingdom)''
    \item \textit{Incorrect Match:} ENGELHARD CORP (via domain mapping)
    \item \textit{Issue:} Historical domain transfer; basf.co.uk no longer owned by BASF SE
    \item \textit{Recommendation:} Remove this specific match
\end{itemize}

These examples demonstrate that homepage domain matching is highly reliable for active, correctly mapped domains. The few errors occur due to domain transfers, corporate restructuring, or data quality issues rather than fundamental flaws in the methodology.

\subsubsection{Comparison with Patent-Firm Matching}

Table~\ref{tab:pub_patent_comparison} compares the publication-firm matching results with the patent-firm matching results. The publication matching achieves higher accuracy (98.7\% vs. 95.4\%) by using only the most reliable matching method. However, it has lower firm coverage (1,580 firms vs. 8,436 firms) because it excludes many smaller firms that lack easily identifiable homepage domains or are not covered in CRSP/Compustat.

\begin{table}[htbp]
\centering
\caption{Comparison: Publication vs Patent Firm Matching}
\label{tab:pub_patent_comparison}
\small
\begin{tabular}{lcc}
\toprule
Statistic & Publications & Patents \\
\midrule
\textbf{Matching Results} & & \\
\quad Total matches & 2,841 & 39,535 \\
\quad Unique firms & 1,580 & 8,436 \\
\quad Matched entities & 2,382 institutions & 31,318 assignees \\
\quad Accuracy & 98.7\% (homepage only) & 95.4\% (all methods) \\
\midrule
\textbf{Coverage} & & \\
\quad Entity coverage & 8.8\% of companies & 32.1\% of assignees \\
\quad Firm coverage & 8.4\% of CRSP & 45.1\% of CRSP \\
\quad Data coverage & 322.4\% of firm papers & 70.0\% of patents \\
\midrule
\textbf{Time Period} & 1990--2024 & 1976--2025 \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Notes: Comparison of publication-firm matching (this section) with patent-firm matching (Section~\ref{subsec:patent_data}). Publication matching uses homepage domain exact matching only (98.7\% accuracy). Patent matching uses multiple methods (95.4\% accuracy). Publication matching covers 2.57 million papers (322\% of firm-affiliated papers), reflecting multiple institutions per paper. Patent matching covers 0.90 million patents (70.0\% of AI patents).}
\end{tabular}
\end{table}

\subsubsection{Data Quality and Limitations}

The publication-firm matching has several limitations that should be noted. First, the homepage domain matching approach requires institutions to have publicly accessible websites with identifiable domains. This may bias the sample toward larger, more established firms and technology companies that maintain active web presences. Second, the CRSP/Compustat database includes only publicly traded US firms, excluding private companies, non-US firms, and firms that were publicly traded during the sample period but have since been acquired or delisted.

Third, institutional coverage in OpenAlex may be incomplete for some companies, particularly for older publications or institutions that have recently undergone restructuring or name changes. Fourth, the matching methodology may miss firms that publish under brands or subsidiary names not reflected in their primary homepage domain.

Despite these limitations, the matching methodology achieves 98.7\% accuracy on manual validation, providing high confidence in the matched dataset. The conservative approach of using only the most reliable matching method (homepage domain exact) ensures minimal false positives while still covering the most active corporate research institutions. This data quality standard meets or exceeds the 95\% target threshold in the literature \citep{arora2021matching, dyevre2023matching}.
