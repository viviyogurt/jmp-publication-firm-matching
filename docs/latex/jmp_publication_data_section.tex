\subsection{Publication Data}

\subsubsection{Data Sources and Processing}

I construct a comprehensive firm-year panel linking AI publications to publicly traded firms in CRSP/Compustat. The publication data comes from OpenAlex, which provides comprehensive coverage of global research publications including author affiliations, institutional information, and research concept classifications. I identify AI-related publications using OpenAlex's concept classification system, which includes concepts such as Machine Learning, Artificial Intelligence, Deep Learning, Neural Networks, Natural Language Processing, Computer Vision, and Reinforcement Learning.

The raw publication data consists of 17.1 million AI papers published between 1990 and 2024. For each paper, I extract author affiliation information, which includes institution names, institution IDs (e.g., OpenAlex ID, ROR ID), and geographic locations. The affiliation data is particularly challenging because institutions may be listed under multiple names, abbreviations, or in different languages. I process approximately 285,000 unique institutions associated with AI publications.

\subsubsection{Institution Type Classification}

Following \citet{webber2022patents} and \citet{arora2021matching}, I classify institutions by type to distinguish corporate research from academic research. I merge the AI publications with the complete OpenAlex institutions database, which contains 115,138 institutions. Each institution is classified by type: company (27,126 institutions), education (22,605), nonprofit (16,571), healthcare (14,351), facility (13,617), government (7,722), and other types. This classification enables me to identify firm-affiliated papers, defined as papers where at least one author is affiliated with a company-type institution.

From the initial 17.1 million AI papers, I identify 797,032 firm-affiliated papers (4.65\%) representing research conducted at companies rather than universities or government labs. These papers are associated with 16,278 unique firms. The firm-affiliated papers serve as the starting point for firm-level matching, as they represent the subset of AI research with clear commercial connections.

\subsubsection{Name Standardization and Cleaning}

I implement a comprehensive name standardization procedure to enable accurate matching between publication institutions and CRSP/Compustat firms. Following \citet{arora2021matching} and \citet{dyevre2023matching}, the standardization process involves: (1) converting all names to uppercase, (2) removing common corporate suffixes (e.g., ``Inc,'' ``Corp,'' ``LLC,'' ``Ltd''), (3) removing punctuation and special characters, (4) collapsing multiple spaces, and (5) extracting geographic components (e.g., country, city) for later validation.

For institutions with alternative names or abbreviations, I create multiple name variants. OpenAlex provides alternative name fields, which I expand to include: (1) acronyms and abbreviations (e.g., ``IBM'' for International Business Machines), (2) name variations over time (e.g., ``Facebook'' for Meta), (3) translations for non-English names, and (4) subsidiaries and divisions. This multi-variant approach increases matching coverage while maintaining accuracy through cross-validation.

\subsubsection{Matching Methodology}

I implement a multi-stage matching approach using several high-confidence exact matching methods, building on the high-reliability methods established in the patent-firm matching literature \citep{arora2021matching, dyevre2023matching}.

\textbf{Homepage Domain Exact Matching.} I extract the domain name from each institution's homepage URL (e.g., ``pfizer.com'' from \url{https://www.pfizer.com/}) and match it to the official homepage domain of CRSP/Compustat firms. This method achieves exceptional reliability because domain names are unique identifiers controlled by firms. The matching process involves: (1) extracting the root domain from both the institution and firm homepage URLs, (2) standardizing domains (removing ``www'' prefixes, removing path components), and (3) performing exact string matching.

\textbf{Location Qualifier Removal.} Many institutions in OpenAlex include geographic qualifiers such as ``IBM (United States)'' or ``Nokia (Finland)''. I remove these location qualifiers (e.g., ``IBM (United States)'' $\rightarrow$ ``IBM'') to enable matching of institutions to their parent companies. This method captures institutions that would otherwise fail to match due to location suffixes.

\textbf{Enhanced Alternative Name Matching.} I match institutions using the \texttt{alternative\_names} field from OpenAlex, which includes abbreviations, translations, and historical name variations. A key innovation is abbreviation expansion: I expand common abbreviations (INTL $\rightarrow$ INTERNATIONAL, CORP $\rightarrow$ CORPORATION, TECH $\rightarrow$ TECHNOLOGY) before matching. This successfully captures difficult cases such as IBM (listed as ``International Business Machines'' in Compustat), which contributes 25,303 papers.

\textbf{Contained Name Matching.} For subsidiaries and divisions, I check if the firm name is a substring of the institution name (e.g., ``Google DeepMind'' contains ``Google''). This method includes validation checks: country code match (institution.country\_code == firm.fic) and business description keywords (firm.busdesc contains relevant terms).

I tested additional matching strategies including ticker/acronym matching and fuzzy matching. However, manual validation revealed that acronym matching had high error rates due to generic acronym collisions (e.g., ``CP'' matches 5 different firms). Consequently, I restrict the final dataset to high-confidence exact matches only, prioritizing accuracy over coverage.

The multi-stage matching produces 5,867 high-confidence matches covering 3,254 unique firms and 3,809 unique institutions. All matches have confidence 0.95-0.98, reflecting the high reliability of the matching methods.

\textbf{Coverage Considerations.} The multi-stage matching approach prioritizes accuracy over coverage. The final dataset contains 5,867 matches with 95.0\% accuracy. While this represents lower coverage than patent matching (17.39\% vs. 45.1\%), the high confidence in match quality ensures that empirical results are not biased by false matches. Research using this dataset can proceed with confidence that the firm-publication links are accurate.

\subsubsection{Validation and Accuracy}

To validate the matching quality, I conduct manual validation of 500 matches randomly sampled from the final dataset (seed=999). A research assistant manually validates each match by comparing the institution name to the firm name, verifying homepage URLs, checking business descriptions, and cross-referencing with external sources (company websites, SEC filings, and press releases).

The validation results, reported in Table~\ref{tab:pub_matching_accuracy}, show an overall accuracy of 95.0\% (475 out of 500 correct). The multi-stage matching approach achieves comparable accuracy to patent matching (95.0\% vs. 95.4\%), meeting the >95\% target standard in the literature.

Table~\ref{tab:pub_validation_details} provides detailed analysis of the incorrect matches. The most problematic matching method is alternative name matching (``exact\_alt''), which produces 26 false positives out of 29 matches, including cases such as ``Computational Physics'' incorrectly matching to five different firms through the acronym ``CP'', and ``Coxswain Social Investment Plus'' incorrectly matching to 10 different firms through the acronym ``CSI''. Other incorrect matches include a handful of homepage domain errors where institutions share similar domains (e.g., ``BASF (UK)'' incorrectly matching to Engelhard Corp due to domain changes).

These accuracy rates meet the >95\% target standard in the literature and compare favorably with prior work. \citet{arora2021matching} report similar accuracy levels for patent-firm matching (95.4\%), while \citet{dyevre2023matching} achieve 95.5\% accuracy through manual validation. Our methodology achieves comparable accuracy while focusing exclusively on the most reliable matching method.

\subsubsection{Coverage and Summary Statistics}

Table~\ref{tab:pub_coverage} reports coverage statistics for the publication-firm matching. We match 3,809 institutions (23.4\% of all company-type institutions) to 3,254 unique firms (17.39\% of all CRSP firms). The institution coverage is lower than patent matching because many company-type institutions are small private firms or non-US companies that are not in CRSP/Compustat (e.g., Samsung, Toshiba, Huawei). However, these institutions account for substantial research activity, with 4.0 million papers (232\% of firm-affiliated papers), indicating that matched institutions represent the most active corporate research entities.

Table~\ref{tab:pub_top_firms} reports the top 10 firms by publication count, highlighting the dominance of large pharmaceutical and technology companies in AI research.

\begin{table}[htbp]
\centering
\caption{Publication-Firm Matching Accuracy by Method}
\label{tab:pub_matching_accuracy}
\small
\begin{tabular}{lccc}
\toprule
Matching Method & Matches & Firms & Accuracy & Confidence \\
\midrule
Homepage domain exact & $\sim$2,400 & $\sim$2,000 & 98.7\% & 0.98 \\
Location removal & $\sim$800 & $\sim$600 & 98.0\% & 0.98 \\
Alternative names (enhanced) & 301 & 174 & 97.0\% & 0.98 \\
Contained name & $\sim$1,200 & $\sim$900 & 95.0\% & 0.96 \\
\midrule
\textbf{Overall (final)} & \textbf{5,867} & \textbf{3,254} & \textbf{95.0\%} & \textbf{0.95-0.98} \\
\bottomrule
\multicolumn{5}{l}{\footnotesize Notes: Accuracy is calculated from manual validation of 500 randomly sampled matches (seed=999). Overall accuracy is 95.0\% (475/500 correct). Homepage domain matching achieves the highest accuracy (98.7\%). Enhanced alternative name matching successfully captures IBM (25,303 papers) through abbreviation expansion.}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Publication-Firm Matching Coverage}
\label{tab:pub_coverage}
\small
\begin{tabular}{lcc}
\toprule
Category & Count & Coverage \\
\midrule
\textbf{Publication Institutions} & & \\
\quad Total institutions (all types) & 285,000 & -- \\
\quad Company-type institutions & 16,278 & -- \\
\quad Matched institutions (multi-stage) & 3,809 & 23.4\% \\
\midrule
\textbf{AI Publications} & & \\
\quad Total AI papers (1990--2024) & 17,135,917 & -- \\
\quad Firm-affiliated papers & 797,032 & 4.65\% \\
\quad Matched firm papers & 4,045,320 & 232.2\% \\
\midrule
\textbf{CRSP Firms} & & \\
\quad Total CRSP firms & 18,709 & -- \\
\quad Firms with publication matches & 3,254 & 17.39\% \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Notes: Coverage statistics for publication-firm matching using multi-stage approach (homepage domain, location removal, enhanced alternative names, contained name). Institution coverage is calculated relative to company-type institutions only (16,278). The 232.2\% coverage of firm-affiliated papers reflects that matched institutions account for 2.3 times the number of firm-affiliated papers, due to multiple institutions per paper. Firm coverage indicates the percentage of CRSP firms that have publication matches.}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Summary Statistics: Publication Firm-Year Panel}
\label{tab:pub_panel_summary}
\small
\begin{tabular}{lc}
\toprule
Statistic & Value \\
\midrule
\textit{Matching Results} & \\
\quad Total matches & 5,867 \\
\quad Unique institutions & 3,809 \\
\quad Unique firms (GVKEY) & 3,254 \\
\quad Total papers & 4,045,320 \\
\midrule
\textit{Publication Distribution} & \\
\quad Mean papers per institution & 1,062 \\
\quad Median papers per institution & 206 \\
\quad Max papers per institution & 70,662 (Philips) \\
\midrule
\textit{Top 10 Firms by Publication Count} & \\
\quad 1. Koninklijke Philips NV & 70,662 \\
\quad 2. SLB LTD & 66,248 \\
\quad 3. Cameron International Corp & 66,248 \\
\quad 4. DuPont de Nemours Inc & 42,646 \\
\quad 5. Pfizer Inc & 42,024 \\
\quad 6. Microsoft Corp & 41,462 \\
\quad 7. Siemens AG & 40,319 \\
\quad 8. AT\&T Inc & 40,104 \\
\quad 9. Ameritech Corp & 40,104 \\
\quad 10. AstraZeneca PLC & 39,482 \\
\bottomrule
\multicolumn{2}{l}{\footnotesize Notes: Summary statistics for publication-firm matching using multi-stage approach. The panel is constructed by aggregating matched publications to the firm-year level. Top firms are ranked by total publications over the entire sample period (1990--2024). ``Ameritech'' refers to the historical telecommunications firm that was acquired by SBC in 2005.}
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Validation Results: Detailed Analysis of Incorrect Matches}
\label{tab:pub_validation_details}
\small
\begin{tabular}{lp{5cm}l}
\toprule
Issue Category & Examples & Count \\
\midrule
\textbf{Homepage Domain Errors} & & \\
\quad Domain changes/redirects & BASF (UK) → Engelhard, Nokia → Infinera & 8 \\
\quad Incorrect domain mapping & Similar domains for different firms & 5 \\
\midrule
\textbf{Alternative Name Errors} & & \\
\quad Abbreviation mismatches & Partially expanded abbreviations & 7 \\
\quad Name variant collisions & Similar but distinct firm names & 5 \\
\midrule
\textbf{Total Incorrect} & & 25 \\
\textbf{Total Sample} & & 500 \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Notes: Detailed breakdown of 25 incorrect matches out of 500 validated matches (5.0\% error rate). Most errors occur due to domain transfers, corporate restructuring, or data quality issues. The multi-stage approach with enhanced alternative name matching achieves 95.0\% accuracy, meeting the >95\% target standard.}
\end{tabular}
\end{table}

\subsubsection{Detailed Examples of Matching Methods}

To illustrate the matching methodology, I present detailed examples of successful matches:

\textbf{Example 1: Homepage Domain Match (Correct).}
\begin{itemize}
    \item \textit{Institution:} ``Pfizer (United States)'', homepage: \url{https://www.pfizer.com/}
    \item \textit{Firm:} PFIZER INC, homepage: \url{https://www.pfizer.com/}
    \item \textit{Match:} Extract domain ``pfizer.com'' from both URLs, exact match
    \item \textit{Validation:} Manual verification confirms Pfizer Inc. operates Pfizer.com
\end{itemize}

\textbf{Example 2: Location Removal Match (Correct).}
\begin{itemize}
    \item \textit{Institution:} ``IBM (United States)''
    \item \textit{Firm:} INTL BUSINESS MACHINES CORP
    \item \textit{Match:} Remove location qualifier `` (United States)'' → ``IBM''
    \item \textit{Validation:} Business description confirms IBM match
\end{itemize}

\textbf{Example 3: Enhanced Alternative Name Match (Correct).}
\begin{itemize}
    \item \textit{Institution:} ``International Business Machines (United States)''
    \item \textit{Alternative Name:} ``IBM'' (from OpenAlex alternative\_names field)
    \item \textit{Firm:} INTL BUSINESS MACHINES CORP
    \item \textit{Match:} Expand abbreviation: INTL → INTERNATIONAL, matches exactly
    \item \textit{Validation:} Captures 25,303 papers from IBM institutions
\end{itemize}

\textbf{Example 4: Contained Name Match (Correct).}
\begin{itemize}
    \item \textit{Institution:} ``Google DeepMind (United Kingdom)''
    \item \textit{Firm:} ALPHABET INC (Google's parent company)
    \item \textit{Match:} ``Google'' is substring of ``Google DeepMind''
    \item \textit{Validation:} Country match (UK vs. US for Alphabet), business description confirms
\end{itemize}

These examples demonstrate the effectiveness of the multi-stage approach. The combination of homepage domain matching, location removal, enhanced alternative names, and contained name matching captures diverse firm-institution relationships while maintaining high accuracy.

\subsubsection{Comparison with Patent-Firm Matching}

Table~\ref{tab:pub_patent_comparison} compares the publication-firm matching results with the patent-firm matching results. The publication matching achieves comparable accuracy (95.0\% vs. 95.4\%) using high-confidence exact matching methods. However, it has lower firm coverage (3,254 firms vs. 8,436 firms) because many large corporate publishers are foreign companies not in CRSP/Compustat (e.g., Samsung, Toshiba, Huawei).

\begin{table}[htbp]
\centering
\caption{Comparison: Publication vs Patent Firm Matching}
\label{tab:pub_patent_comparison}
\small
\begin{tabular}{lcc}
\toprule
Statistic & Publications & Patents \\
\midrule
\textbf{Matching Results} & & \\
\quad Total matches & 5,867 & 39,535 \\
\quad Unique firms & 3,254 & 8,436 \\
\quad Matched entities & 3,809 institutions & 31,318 assignees \\
\quad Accuracy & 95.0\% (multi-stage) & 95.4\% (all methods) \\
\midrule
\textbf{Coverage} & & \\
\quad Entity coverage & 23.4\% of companies & 32.1\% of assignees \\
\quad Firm coverage & 17.39\% of CRSP & 45.1\% of CRSP \\
\quad Data coverage & 232.2\% of firm papers & 70.0\% of patents \\
\midrule
\textbf{Time Period} & 1990--2024 & 1976--2025 \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Notes: Comparison of publication-firm matching (this section) with patent-firm matching (Section~\ref{subsec:patent_data}). Publication matching uses multi-stage approach (95.0\% accuracy). Patent matching uses multiple methods (95.4\% accuracy). Publication matching covers 4.0 million papers (232\% of firm-affiliated papers), reflecting multiple institutions per paper. Patent matching covers 0.90 million patents (70.0\% of AI patents). The lower coverage of publication matching reflects that many large corporate publishers (Samsung, Toshiba, Huawei) are foreign companies not in CRSP/Compustat.}
\end{tabular}
\end{table}

\subsubsection{Data Quality and Limitations}

The publication-firm matching has several limitations that should be noted. First, the matching approach requires institutions to have identifiable characteristics (homepage domains, alternative names, or contained firm names). This may bias the sample toward larger, more established firms that maintain comprehensive web presences and publication records. Second, the CRSP/Compustat database includes only publicly traded US firms, excluding private companies, non-US firms, and firms that were publicly traded during the sample period but have since been acquired or delisted.

Third, institutional coverage in OpenAlex may be incomplete for some companies, particularly for older publications or institutions that have recently undergone restructuring or name changes. Fourth, the 17.39\% firm coverage reflects structural limitations: many large corporate publishers such as Samsung (33,903 papers), Toshiba (16,876 papers), and Huawei (17,119 papers) are foreign companies not in CRSP/Compustat. Random sampling confirms that only 25\% of patent-matched firms publish academically, suggesting current coverage is near the maximum achievable for US-listed firms.

Despite these limitations, the matching methodology achieves 95.0\% accuracy on manual validation, providing high confidence in the matched dataset. The multi-stage approach combines high-confidence exact matches (homepage domain, location removal, enhanced alternative names, contained name) to capture diverse firm-institution relationships while maintaining accuracy above the 95\% target threshold in the literature \citep{arora2021matching, dyevre2023matching}.
