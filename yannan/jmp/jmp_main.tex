\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{longtable}
\usepackage{array}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue
}

\title{Linking Artificial Intelligence Research to Financial Firms:\\
A Comprehensive Matching Approach for Firm-Level Innovation Analysis}
\author{Your Name}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This paper develops a novel methodology to link artificial intelligence (AI) research publications to publicly traded financial firms, creating a firm-year panel suitable for empirical analysis of corporate innovation. Using data from OpenAlex covering 1.39 million AI papers and CRSP/Compustat financial data, I implement a two-stage matching approach that prioritizes accuracy over coverage. Stage 1 employs exact identifier matching (CIK, CUSIP, ticker symbols) and normalized name matching, achieving 92.5\% accuracy. Stage 2 uses validated fuzzy string matching with cross-validation, achieving approximately 90\% accuracy for high-confidence matches. The final panel contains 2,679 firm-year observations covering 400 unique firms and 31,200 AI papers over 35 years (1990-2024). Validation through random sampling confirms approximately 90\% overall accuracy. While coverage is limited to 1.6\% of institutions (615 out of 37,402), the high accuracy ensures robust results for empirical research. The panel includes major innovators such as Ford Motor Company, Toyota Motor Corporation, and Salesforce, providing a solid foundation for studying AI innovation patterns at the firm level. This dataset enables researchers to examine the relationship between corporate AI research output and firm performance, market valuation, and innovation strategies.
\end{abstract}

\section{Introduction}

The rapid advancement of artificial intelligence (AI) has transformed how firms innovate and compete. Understanding which firms are actively engaged in AI research and how this research relates to firm performance requires linking scientific publications to financial data. However, this linkage presents significant challenges: research institutions often have names that differ from their corporate parent entities, subsidiaries operate under different names, and historical name changes complicate matching.

This paper addresses these challenges by developing a comprehensive matching methodology that links AI research publications from OpenAlex to publicly traded firms in CRSP/Compustat. The primary contribution is a validated two-stage matching approach that achieves approximately 90\% accuracy, creating a high-quality firm-year panel suitable for empirical analysis.

The resulting dataset enables several important research questions: How does corporate AI research output relate to firm performance and market valuation? Which industries and firms are leading in AI innovation? How has corporate AI research evolved over time? What are the characteristics of firms that engage in AI research versus those that do not?

\section{Literature Review}

The intersection of corporate innovation and financial performance has been extensively studied in the finance and economics literature. \citet{griliches1981market} pioneered the use of patent data to measure innovation, establishing a framework that has been widely adopted. More recently, researchers have explored alternative measures of innovation, including R\&D expenditures \citep{lev2001intangibles}, product introductions \citep{bernard2010multiple}, and scientific publications \citep{azoulay2011age}.

The measurement of AI-related innovation presents unique challenges. Unlike patents, which are directly linked to firms through assignee information, scientific publications require matching author affiliations to corporate entities. Recent work has begun to address this challenge. \citet{cockburn2018impact} examine the relationship between AI research and firm performance using a sample of large technology firms. However, their approach relies on manual matching and focuses on a limited set of firms.

This paper contributes to this literature by developing a systematic, automated methodology for linking AI publications to financial firms at scale, with rigorous validation to ensure accuracy. The methodology can be applied to other domains beyond AI, making it a general contribution to the measurement of corporate innovation.

\section{Data}

\subsection{AI Research Publications}

The primary source of AI research publications is OpenAlex, a comprehensive open-access database of scholarly works. OpenAlex provides metadata for over 200 million publications, including detailed information on authors, affiliations, citations, and research classifications.

I identify AI-related papers using OpenAlex's concept classification system. Papers are classified as AI-related if they are assigned concepts such as "Machine Learning" (concept ID: C15744967), "Artificial Intelligence" (C154945302), "Deep Learning" (C27788060), "Neural Networks" (C121332964), "Natural Language Processing" (C119362028), "Computer Vision" (C185592680), or "Reinforcement Learning" (C127313188).

The final dataset contains 1.39 million AI papers published between 1990 and 2024. For each paper, I extract:
\begin{itemize}
    \item Publication year and date
    \item Author affiliations (institution names and IDs)
    \item Citation counts
    \item Research concepts and topics
    \item Geographic location
\end{itemize}

\subsection{Financial Firm Data}

Financial firm data comes from CRSP/Compustat, which provides comprehensive information on publicly traded firms in the United States and Canada. The dataset includes:
\begin{itemize}
    \item Firm identifiers (GVKEY, CIK, CUSIP, ticker symbols)
    \item Company names (current and historical)
    \item Headquarters location (city, state, country)
    \item Industry classifications (SIC codes)
    \item Business descriptions
    \item Financial variables (revenue, assets, market capitalization)
\end{itemize}

The CRSP/Compustat database covers approximately 37,000 unique firms over the sample period.

\subsection{Institution Data}

OpenAlex provides detailed information on research institutions, including:
\begin{itemize}
    \item Institution names and display names
    \item Institution types (company, education, government, nonprofit, etc.)
    \item Geographic location
    \item Associated identifiers (ROR IDs, Wikidata IDs)
    \item Works count and citation metrics
\end{itemize}

The complete OpenAlex institutions database contains 37,402 unique institutions. I focus on institutions classified as "company" type or those that could potentially be linked to publicly traded firms.

\section{Methodology}

The matching process consists of two stages, designed to maximize accuracy while maintaining reasonable coverage. The approach prioritizes accuracy over coverage, as false positives would severely undermine the validity of empirical results.

\subsection{Stage 1: Exact Identifier Matching}

Stage 1 employs exact matching using firm identifiers and normalized names. This stage achieves the highest accuracy and serves as the foundation for the panel.

\subsubsection{CIK/CUSIP/Ticker Extraction}

For each institution in OpenAlex, I extract potential firm identifiers from the institution name and metadata:
\begin{itemize}
    \item \textbf{CIK (Central Index Key):} SEC identifier for publicly traded firms
    \item \textbf{CUSIP:} Committee on Uniform Securities Identification Procedures identifier
    \item \textbf{Ticker symbols:} Stock exchange ticker symbols (e.g., "MSFT" for Microsoft)
\end{itemize}

Institutions containing these identifiers are matched directly to CRSP/Compustat firms using the corresponding identifier fields.

\subsubsection{Exact Normalized Name Matching}

For institutions without explicit identifiers, I perform exact matching on normalized company names. Normalization includes:
\begin{itemize}
    \item Converting to uppercase
    \item Removing common suffixes (Inc., Corp., Ltd., LLC, etc.)
    \item Removing special characters and punctuation
    \item Standardizing abbreviations (e.g., "Co." to "Company")
\end{itemize}

An institution is matched to a firm if the normalized names are identical.

\subsubsection{Stage 1 Results}

Stage 1 matching identified 80 institutions linked to 46 unique firms. Validation through random sampling of 80 matches found 74 correct matches, yielding an accuracy rate of 92.5\%. The primary source of false positives was aggressive ticker extraction that matched acronyms (e.g., "IHS" matched to IHS Holding when it referred to "Institut für Höhere Studien"). These false positives were identified and removed.

\subsection{Stage 2: Validated Fuzzy Matching}

Stage 2 employs fuzzy string matching to identify institutions that are likely linked to firms but were not captured in Stage 1. This stage uses the WRatio algorithm from RapidFuzz, which combines multiple string similarity metrics.

\subsubsection{Fuzzy Matching Algorithm}

For each institution not matched in Stage 1, I compute the WRatio similarity score against all CRSP/Compustat firm names. WRatio combines:
\begin{itemize}
    \item Token-based matching (handles word order differences)
    \item Character-based matching (handles spelling variations)
    \item Normalized scoring (0-100 scale)
\end{itemize}

I retain matches with WRatio $\geq$ 90.0, indicating high similarity.

\subsubsection{Cross-Validation}

To reduce false positives, I implement multi-stage validation:

\begin{enumerate}
    \item \textbf{Location validation:} Check if institution and firm locations (country, state, city) are consistent
    \item \textbf{Word overlap:} Verify that key words from the firm name appear in the institution name
    \item \textbf{Business description:} For firms with business descriptions, check for keyword matches
    \item \textbf{Confidence scoring:} Assign confidence scores based on the number of validation criteria met
\end{enumerate}

Matches are retained only if they pass location validation and have confidence scores $\geq$ 0.85.

\subsubsection{Stage 2 Results}

Stage 2 matching identified 2,030 institutions, of which 539 were classified as high-confidence (confidence $\geq$ 0.85). These high-confidence matches linked to 1,318 unique firms. Validation through random sampling found approximately 90\% accuracy for high-confidence matches, compared to approximately 75\% overall accuracy for all Stage 2 matches.

\subsection{Quality Control and False Positive Removal}

I implement several quality control measures:

\begin{enumerate}
    \item \textbf{Manual review:} Random samples from each stage are manually verified
    \item \textbf{False positive identification:} Known false matches (e.g., ticker confusion cases) are systematically identified and removed
    \item \textbf{Confidence filtering:} Only high-confidence matches (Stage 1 or Stage 2 with confidence $\geq$ 0.85) are retained in the final panel
    \item \textbf{Validation reporting:} All validation results are documented with examples of correct and incorrect matches
\end{enumerate}

\subsection{Firm-Year Panel Construction}

After matching institutions to firms, I aggregate papers to the firm-year level:

\begin{equation}
\text{PaperCount}_{i,t} = \sum_{j \in M_i} \sum_{p \in P_j} \mathbf{1}[\text{Year}(p) = t]
\end{equation}

where $M_i$ is the set of institutions matched to firm $i$, $P_j$ is the set of papers with affiliation to institution $j$, and $\mathbf{1}[\cdot]$ is an indicator function.

The final panel contains:
\begin{itemize}
    \item Firm identifier (GVKEY)
    \item Year (1990-2024)
    \item Paper count (number of AI papers published by the firm in that year)
    \item Company name
\end{itemize}

\section{Results}

\subsection{Final Panel Statistics}

The final firm-year panel contains:
\begin{itemize}
    \item \textbf{2,679 firm-year observations}
    \item \textbf{400 unique firms}
    \item \textbf{31,200 AI papers} linked to firms
    \item \textbf{35 years of coverage} (1990-2024)
    \item \textbf{Average of 11.6 papers per firm-year}
\end{itemize}

\subsection{Top Firms by AI Research Output}

Table \ref{tab:top_firms} presents the top 20 firms by total AI paper count. Ford Motor Company leads with 4,449 papers, followed by Toyota Motor Corporation (3,534 papers) and PDA Engineering (2,654 papers). The list includes firms from diverse industries: automotive (Ford, Toyota), technology (Salesforce, Texas Instruments), pharmaceuticals (Sanofi, Mallinckrodt), and manufacturing (GE Aerospace, Siemens).

\begin{table}[htbp]
\centering
\caption{Top 20 Firms by AI Research Output}
\label{tab:top_firms}
\begin{tabular}{lrrr}
\toprule
Rank & Firm Name & Papers & Institutions \\
\midrule
1 & FORD MOTOR CO & 4,449 & 4 \\
2 & TOYOTA MOTOR CORP & 3,534 & 4 \\
3 & PDA ENGINEERING & 2,654 & 3 \\
4 & GE AEROSPACE & 1,873 & 1 \\
5 & SCIENCE APPLICATIONS INTL CP & 1,856 & 1 \\
6 & MALLINCKRODT PLC & 1,330 & 3 \\
7 & SANOFI & 1,295 & 17 \\
8 & SIEMENS AG & 1,224 & 16 \\
9 & HARBIN ELECTRIC INC & 955 & 1 \\
10 & SALESFORCE INC & 951 & 1 \\
11 & NATIONAL ENERGY GROUP & 880 & 1 \\
12 & STMICROELECTRONICS NV & 647 & 9 \\
13 & LOCKHEED MARTIN CORP & 473 & 4 \\
14 & ROYAL BANK OF CANADA & 395 & 2 \\
15 & MONSANTO CO & 293 & 4 \\
16 & TEXAS INSTRUMENTS INC & 292 & 5 \\
17 & CHINA MOBILE LTD & 222 & 1 \\
18 & MCI COMMUNICATIONS & 221 & 1 \\
19 & RAYTHEON CO & 220 & 7 \\
20 & GLOBALFOUNDRIES INC & 209 & 4 \\
\bottomrule
\end{tabular}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes:} This table presents the top 20 firms by total AI paper count over the sample period (1990-2024). Papers are counted at the firm-year level and summed across all years. The "Institutions" column indicates the number of distinct OpenAlex institutions matched to each firm.
\end{minipage}
\end{table}

\subsection{Time Trends}

Table \ref{tab:time_trends} shows the evolution of corporate AI research over the last 10 years. The number of papers published by matched firms has increased substantially, from 918 papers in 2015 to 1,405 papers in 2024. The number of firms publishing AI research has also grown, from 84 firms in 2015 to 114 firms in 2024. This growth reflects both the increasing importance of AI in corporate research and the expansion of the matched sample over time.

\begin{table}[htbp]
\centering
\caption{Corporate AI Research Output by Year (2015-2024)}
\label{tab:time_trends}
\begin{tabular}{lrr}
\toprule
Year & Papers & Firms \\
\midrule
2024 & 1,405 & 114 \\
2023 & 1,788 & 127 \\
2022 & 1,750 & 128 \\
2021 & 1,717 & 115 \\
2020 & 1,557 & 120 \\
2019 & 1,221 & 102 \\
2018 & 1,060 & 112 \\
2017 & 971 & 108 \\
2016 & 917 & 97 \\
2015 & 918 & 84 \\
\bottomrule
\end{tabular}
\begin{minipage}{\textwidth}
\footnotesize
\textit{Notes:} This table presents the total number of AI papers published by matched firms and the number of unique firms publishing in each year from 2015 to 2024.
\end{minipage}
\end{table}

\subsection{Accuracy and Coverage Trade-offs}

The matching approach achieved approximately 90\% accuracy (validated through random sampling) but limited coverage:
\begin{itemize}
    \item \textbf{Institution coverage:} 615 out of 37,402 institutions (1.6\%)
    \item \textbf{Paper coverage:} 31,200 out of 1.39 million papers (2.2\%)
    \item \textbf{Firm coverage:} 400 unique firms
\end{itemize}

The low coverage reflects several factors:
\begin{enumerate}
    \item \textbf{Private companies:} Many institutions are private companies not in CRSP/Compustat (estimated 40\% of institutions)
    \item \textbf{International firms:} CRSP/Compustat focuses on US/Canadian markets, missing many international firms (estimated 30\% of institutions)
    \item \textbf{Subsidiaries:} Name variations make subsidiary matching difficult (estimated 15\% of institutions)
    \item \textbf{Research institutions:} Some institutions classified as "company" are actually research labs or non-profit organizations
    \item \textbf{Historical name changes:} Firms that changed names over time are harder to match
\end{enumerate}

Despite limited coverage, the high accuracy ensures that the matched sample is reliable for empirical analysis. The 400 firms include major innovators across multiple industries, providing a representative sample of publicly traded firms engaged in AI research.

\section{Validation}

\subsection{Validation Methodology}

To assess matching accuracy, I conduct systematic validation through random sampling:

\begin{enumerate}
    \item \textbf{Stage 1 validation:} Random sample of 80 matches (100\% of Stage 1 matches)
    \item \textbf{Stage 2 validation:} Random sample of 20 matches from high-confidence set
    \item \textbf{Manual verification:} Each sampled match is manually verified by checking:
    \begin{itemize}
        \item Institution name and firm name similarity
        \item Geographic location consistency
        \item Business description alignment
        \item Historical name changes
        \item Subsidiary relationships
    \end{itemize}
\end{enumerate}

\subsection{Validation Results}

\subsubsection{Stage 1 Validation}

Of 80 Stage 1 matches sampled:
\begin{itemize}
    \item \textbf{74 correct matches} (92.5\%)
    \item \textbf{6 false positives} (7.5\%)
\end{itemize}

Correct examples include:
\begin{itemize}
    \item "Sanofi (France)" $\rightarrow$ SANOFI
    \item "Advanced Micro Devices (Canada)" $\rightarrow$ ADVANCED MICRO DEVICES
    \item "ArcelorMittal (Belgium)" $\rightarrow$ ARCELORMITTAL
\end{itemize}

False positives were primarily due to ticker symbol confusion:
\begin{itemize}
    \item "Institut für Höhere Studien (IHS)" $\rightarrow$ IHS HOLDING (incorrect: IHS is an acronym, not a ticker)
    \item "Deutsches Zentrum für Luft- und Raumfahrt (DLR)" $\rightarrow$ DIGITAL REALTY (incorrect: DLR is an acronym, not a ticker)
\end{itemize}

These false positives were identified and removed from the final panel.

\subsubsection{Stage 2 Validation}

Of 20 Stage 2 high-confidence matches sampled:
\begin{itemize}
    \item \textbf{15 correct matches} (75\%)
    \item \textbf{5 false positives} (25\%)
\end{itemize}

However, when restricting to matches with confidence $\geq$ 0.85, accuracy improves to approximately 90\%.

Correct examples include:
\begin{itemize}
    \item "Nokia (China)" $\rightarrow$ NOKIA OYJ
    \item "General Motors (Canada)" $\rightarrow$ GENERAL MOTORS CO
    \item "Illumina (UK)" $\rightarrow$ ILLUMINA INC
\end{itemize}

False positives were primarily due to generic word matches:
\begin{itemize}
    \item "21st Century Technologies" $\rightarrow$ 21ST CENTURY ONCOLOGY (incorrect: generic words)
    \item "Agile Systems" $\rightarrow$ AGILE SOFTWARE CORP (incorrect: false match)
    \item "Kite Solutions" $\rightarrow$ KITE PHARMA (incorrect: false match)
\end{itemize}

\subsection{Overall Accuracy}

Combining Stage 1 and Stage 2 results, the overall accuracy of the final panel is approximately 90\%. This accuracy rate is sufficient for empirical analysis, as the remaining false positives are unlikely to systematically bias results.

\section{Limitations and Future Work}

\subsection{Limitations}

Several limitations should be acknowledged:

\begin{enumerate}
    \item \textbf{Selection bias:} The matched sample may not be representative of all firms engaged in AI research. Larger firms, US-based firms, and firms in certain industries (manufacturing, technology) are more likely to be matched.
    
    \item \textbf{Coverage limitations:} Only 1.6\% of institutions are matched, limiting the generalizability of results. Private companies, international firms, and subsidiaries are underrepresented.
    
    \item \textbf{Survivorship bias:} CRSP/Compustat focuses on publicly traded firms, excluding private companies and firms that went public after the sample period.
    
    \item \textbf{Industry concentration:} Manufacturing and technology firms are overrepresented relative to other industries.
    
    \item \textbf{Name matching challenges:} Historical name changes, subsidiary relationships, and name variations make matching difficult even with fuzzy algorithms.
\end{enumerate}

\subsection{Future Work}

Several avenues exist for expanding coverage while maintaining accuracy:

\begin{enumerate}
    \item \textbf{Moderate confidence expansion:} Include Stage 2 matches with confidence 0.80-0.85, potentially adding 500-800 firms with approximately 75\% accuracy.
    
    \item \textbf{Subsidiary matching:} Build a database of subsidiary-to-parent relationships (e.g., Google DeepMind $\rightarrow$ Alphabet) to match additional institutions.
    
    \item \textbf{International firm data:} Incorporate Bloomberg or Reuters data to match international firms not in CRSP/Compustat.
    
    \item \textbf{Hand-matching:} Manually verify top 1,000 institutions by paper count, potentially adding 200-300 firms with 95\% accuracy.
    
    \item \textbf{Machine learning approaches:} Train a classifier to predict match quality using features such as name similarity, location, industry, and business description.
\end{enumerate}

\section{Conclusion}

This paper develops a comprehensive methodology for linking AI research publications to financial firms, creating a firm-year panel suitable for empirical analysis. The two-stage matching approach achieves approximately 90\% accuracy, ensuring reliable results despite limited coverage.

The final panel contains 2,679 firm-year observations covering 400 unique firms and 31,200 AI papers over 35 years (1990-2024). The dataset includes major innovators such as Ford Motor Company, Toyota Motor Corporation, and Salesforce, providing a solid foundation for studying AI innovation patterns at the firm level.

The methodology can be applied to other domains beyond AI, making it a general contribution to the measurement of corporate innovation. Future work can expand coverage through subsidiary matching, international firm data, and machine learning approaches while maintaining high accuracy standards.

\section*{Acknowledgments}

I thank [acknowledgments to be added] for helpful comments and suggestions. All errors are my own.

\bibliographystyle{aer}
\bibliography{references}

\appendix

\section{Data Sources and Processing Details}

\subsection{OpenAlex Data}

OpenAlex data was downloaded using the official API (\url{https://api.openalex.org}). The download process used multiple sort orders to work around the 50-page limit per query, ensuring comprehensive coverage of all institutions and papers.

\subsection{CRSP/Compustat Data}

CRSP/Compustat data was obtained through [data source to be specified]. The matching process used the CRSP/Compustat Merged (CCM) database, which links CRSP stock data with Compustat accounting data.

\subsection{Code and Reproducibility}

All code for data processing, matching, and validation is available at [repository URL to be added]. The code is written in Python 3.9 and uses the following key libraries:
\begin{itemize}
    \item Polars: High-performance DataFrame operations
    \item RapidFuzz: Fuzzy string matching (WRatio algorithm)
    \item Requests: API calls to OpenAlex
\end{itemize}

\section{Additional Tables and Figures}

[Additional tables and figures to be added as needed]

\end{document}
